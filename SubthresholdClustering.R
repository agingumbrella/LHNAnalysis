# Making a start on clustering subthreshold membrane potential responses to odours

ShaharDataRoot="/Users/shahar/Data"

physplit=read.table("/Volumes/Shahar_External/Database/PhySplitSimple.mer",sep=',',header=TRUE,stringsAsFactors=FALSE)
# calculate name of cell from Igor file column
physplit$cell=basename(physplit$Igor.file)
#load("~/projects/Shahar/RandIgor/physplit.rda")
ps=subset(physplit,cluster_Analyze!="")
# for the moment, just keep cells where we have the same number of sweeps and a valid path
ps=subset(ps,nchar(cluster_Analyze)==14)

# now we need to load the average files for these selected cells
# names look like "002_Avg_RG0_A0++.txt"
# ODD file looks like nm20120703c2_018_odd_Sput_1_6sec.txt

source("ClusteringFunctions.R")

badcells=c("nm20120131c0","nm20120216c0","nm20120711c2")

if(!exists('smoothed_traces'))
  smoothed_traces=list()
for(i in seq(ps$Igor.file)){
  igorpath=ps$Igor.file[i]
  # name of the cell is the folder name without preceding path
  cell=basename(igorpath)
  # if we've already read this cell or it's a bad cell then just keep going
  if(cell%in%names(smoothed_traces) || cell %in% badcells) next
  selsweeps=unlist(strsplit(ps$cluster_Analyze[i],","))
  thiscelllist=list()
  message("Reading data for cell:",cell)
  for(sweep in selsweeps){
    odf=oddfilename(igorpath,sweep)
    if(!file.exists(odf)){
      message("Cannot find ODD config file for ",igorpath,' sweep ',sweep)
      next
    }
    odd<-read.odd(odf)
    # remove duplicate odour blocks
    odd<-subset(odd,!duplicated(odour))

    avgfile=avgname(igorpath,sweep)
    if(!file.exists(avgfile)){
      message("Cannot find Average file for",igorpath,' sweep ',sweep)
      next
    }
    Avg<-read.table(avgfile,header=TRUE)
    colnames(Avg)=odd$odour
    sputnum=sputniknumber(igorpath,sweep)
    thiscelllist[[sputnum]]=Avg
  }
  smoothed_traces[[cell]]=do.call(cbind,thiscelllist)
}

# goodcells=setdiff(names(smoothed_traces),badcells)
# message("Removing ",length(badcells)," cells leaving ", length(goodcells))

message("Converting ",length(smoothed_traces),' cells to time series')
l_T=lapply(smoothed_traces,ts,start=0,freq=10000)
# filter - simple boxcar filter 1000 points => 100 ms
# window to get rid of nas?
# decimate factor of 100 ie go from 10kHz to 100 Hz sample rate

# nb top and tail 100ms in order to avoid NAs generated by filter
message("Smoothing and downsampling",length(l_T),'cells')
l_Tf=lapply(l_T,smooth_decimate,filterlength=1000,downsamplefactor=100,start=0.05,end=2.9)
message("Calculating baseline for ",length(l_Tf), 'cells')
l_base=lapply(l_Tf,function(x) {baseline=window(x,start=0.1,end=0.4);scale.default(x,center=colMeans(baseline),scale=FALSE)})
# concatenate responses for all odours for one cell in one column
# ie rows are different timepoints
concat=do.call(cbind,lapply(l_base,as.vector))
# find correlation between all pairs of columns (ie cells)
cp=cor(concat,use='complete.obs')

# dendrogram + image of correlations scores between each neuron
# NO! BAD IDEA since dendrograms will have most different neurons next to each other
# and vice versa
# heatmap(cp,scale='none',symm=T,col=jet.colors(20))

# INSTEAD DO THIS:
# heatmap directly uses distance based on 1-correlation score 
heatmap(1-cp,distfun=as.dist,scale='none',symm=T,col=jet.colors(20))
# dendrogram is based on distance of 1-correlation score, but the 
# colours in the heatmap are still the correlation scores (ie hot is highly correlated)
heatmap(cp,distfun=function(x) as.dist(1-x),scale='none',symm=T,col=jet.colors(20))

# find crosses for all those cells that we have plotted
crosses=physplit$cross[match(rownames(cp),physplit$cell)]
heatmap(cp,distfun=function(x) as.dist(1-x),scale='none',symm=T,col=jet.colors(20),labRow=crosses)

l_Tf2=lapply(l_Tf,smooth_decimate,filterlength=20,downsamplefactor=10,start=0.05,end=2.9)
l_base2=lapply(l_Tf2,function(x) {baseline=window(x,start=0.1,end=0.4);scale.default(x,center=colMeans(baseline),scale=FALSE)})
concat2=do.call(cbind,lapply(l_base2,as.vector))
# find correlation between all pairs of columns (ie cells)
cp2=cor(concat2,use='complete.obs')


# clustering based on Euclidean distance between responses of each to neuron
# to all odours (~ 1500 dimensional space after downsampling to 10Hz)
stop()

timepts_perodour=dim(l_Tf2[[1]])[1]
nodours=dim(l_Tf2[[1]])[2]
heatmap(concat2,col=jet.colors(20),scale='none',Rowv=NA,RowSideColors=rep(as.character(rainbow(nodours)),each=timepts_perodour))